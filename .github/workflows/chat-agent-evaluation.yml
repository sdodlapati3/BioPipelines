name: Chat Agent Evaluation

on:
  push:
    branches: [main, develop]
    paths:
      - 'src/agents/**'
      - 'src/workflow_composer/**'
      - 'tests/evaluation/**'
      - 'config/**'
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      full_evaluation:
        description: 'Run full evaluation (not quick mode)'
        required: false
        default: 'false'
      create_baseline:
        description: 'Create new baseline from this run'
        required: false
        default: 'false'

jobs:
  evaluate:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-composer.txt
          pip install pytest pytest-asyncio
      
      - name: Run quick evaluation
        if: github.event.inputs.full_evaluation != 'true'
        run: |
          python scripts/ci_test.py --quick
        env:
          PYTHONPATH: ${{ github.workspace }}/src
      
      - name: Run full evaluation
        if: github.event.inputs.full_evaluation == 'true'
        run: |
          python scripts/ci_test.py
        env:
          PYTHONPATH: ${{ github.workspace }}/src
      
      - name: Create baseline
        if: github.event.inputs.create_baseline == 'true'
        run: |
          python scripts/ci_test.py --create-baseline
        env:
          PYTHONPATH: ${{ github.workspace }}/src
      
      - name: Run error analysis
        if: always()
        run: |
          python scripts/error_pattern_analyzer.py || true
        env:
          PYTHONPATH: ${{ github.workspace }}/src
      
      - name: Upload evaluation results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: evaluation-results
          path: |
            reports/evaluation/*.json
            reports/evaluation/*.html
            reports/evaluation/*.md
          retention-days: 30
      
      - name: Upload baseline
        uses: actions/upload-artifact@v4
        if: github.event.inputs.create_baseline == 'true'
        with:
          name: baseline
          path: reports/evaluation/baseline.json
          retention-days: 90

  notify-on-failure:
    runs-on: ubuntu-latest
    needs: evaluate
    if: failure()
    
    steps:
      - name: Create issue for regression
        uses: actions/github-script@v7
        with:
          script: |
            const title = `Chat Agent Evaluation Regression - ${new Date().toISOString().split('T')[0]}`;
            const body = `
            ## ðŸ”´ Evaluation Regression Detected
            
            The chat agent evaluation pipeline detected a regression or failure.
            
            **Workflow Run:** [${context.runNumber}](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            **Triggered by:** ${context.eventName}
            **Branch:** ${context.ref}
            
            ### Next Steps
            1. Check the [workflow logs](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            2. Download the evaluation artifacts for detailed analysis
            3. Run \`python scripts/error_pattern_analyzer.py\` locally
            4. Fix the identified issues and re-run tests
            
            cc @${context.actor}
            `;
            
            // Check if similar issue exists
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: 'evaluation-regression',
              state: 'open'
            });
            
            if (issues.data.length === 0) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['evaluation-regression', 'automated']
              });
            }
