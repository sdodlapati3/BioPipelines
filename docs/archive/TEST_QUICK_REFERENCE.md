# BioPipelines Testing Quick Reference - Nov 26, 2025

## ‚ö° Quick Start

### Environment Setup
```bash
# Navigate to workspace
cd /home/sdodl001_odu_edu/BioPipelines

# Activate Python environment
conda activate biopipelines  # or your environment

# Install in dev mode if not already
pip install -e .

# Verify LLM server available
curl http://localhost:11434/api/tags  # Ollama
# or check OpenAI/Anthropic API keys
echo $OPENAI_API_KEY
```

### Run All Tests
```bash
# Show manual checklist
python test_runner.py --manual

# Run all automated tests
python test_runner.py --all -v

# Run specific component
python test_runner.py --components diagnosis -v

# Save results
python test_runner.py --all --save
```

---

## üìã Testing Components

### 1Ô∏è‚É£ FRONTEND (15 min)
```bash
# Start UI
python -m workflow_composer.web

# Or if that doesn't work
cd src && python -c "from workflow_composer.web import create_app; app = create_app(); app.launch()"

# Then navigate to: http://localhost:7860
```

**Quick Test:**
- [x] Tab 1: Type "RNA-seq human" ‚Üí Submit
- [x] Tab 2: Upload `.nextflow.log` file from `tests/test_data/`
- [x] Tab 3: Browse to `data/results/`
- [x] Tab 4: Search "human ChIP-seq"

### 2Ô∏è‚É£ INTENT PARSING (5 min)
```bash
pytest tests/test_workflow_composer.py::TestImports -v
```

**Expected Outputs:**
| Query | Analysis Type | Organism | Confidence |
|-------|--------------|----------|-----------|
| "RNA-seq human" | RNA_SEQ_DE | hsa | 0.95+ |
| "ChIP-seq H3K27ac" | CHIP_SEQ | None | 0.90+ |
| "mouse brain scRNA-seq" | SCRNA_SEQ | mmu | 0.95+ |

### 3Ô∏è‚É£ TOOL SELECTION (5 min)
```bash
pytest tests/test_integration.py::TestComposerIntegration -v
```

**Expected Mapping:**
```
RNA-seq          ‚Üí nf-core/rnaseq
ChIP-seq         ‚Üí nf-core/chipseq
ATAC-seq         ‚Üí nf-core/atacseq
scRNA-seq        ‚Üí nf-core/scrnaseq
WGS              ‚Üí nf-core/sarek
Metagenomics     ‚Üí nf-core/mag
```

### 4Ô∏è‚É£ MODULE MAPPING (10 min)
```bash
pytest tests/test_workflow_composer.py::TestConfig -v
pytest tests/test_workflow_composer.py::TestDataDownloader -v
```

**Check:**
- [ ] Modules load from nf-core
- [ ] Default parameters sensible
- [ ] Version conflicts detected

### 5Ô∏è‚É£ WORKFLOW GENERATION (10 min)
```bash
# Test with a generated workflow
cd generated_workflows/
nextflow lint chipseqpeakcalling_20251125_201817/main.nf

# Try to preview config
nextflow config chipseqpeakcalling_20251125_201817/main.nf 2>&1 | head -20
```

**Verify:**
- [ ] No syntax errors in main.nf
- [ ] Config file valid YAML
- [ ] All imports resolve

### 6Ô∏è‚É£ EXECUTION (15 min)
```bash
# Submit test job
cd generated_workflows/workflow_20251125_092924/
sbatch submit.sh

# Check status
squeue -u $USER

# Tail logs
tail -f .nextflow.log
```

**Monitor:**
- [ ] Job ID returned
- [ ] Job appears in squeue
- [ ] CPU/memory allocation appropriate

### 7Ô∏è‚É£ MONITORING (10 min)
```bash
# Watch job progress
watch -n 5 'squeue -u $USER'

# Check logs in real-time
tail -f .nextflow.log | grep -E "ERROR|WARN|Completed"

# Get job stats
sstat -j <JOBID> --format=JobID,MaxRSS,Elapsed
```

**Verify:**
- [ ] Status updates every 30s
- [ ] CPU/memory tracking works
- [ ] Log tail readable

### 8Ô∏è‚É£ DIAGNOSIS (10 min)
```bash
pytest tests/test_diagnosis.py::TestErrorDiagnosisAgent -v
```

**Test Errors:**
```bash
# OOM Error
echo "slurmstepd: error: Detected 1 oom-kill event(s)" | python -c \
  "from workflow_composer.diagnosis import ErrorDiagnosisAgent; agent = ErrorDiagnosisAgent(); import asyncio; print(asyncio.run(agent.diagnose(input())))"

# File Not Found
echo "ERROR: File not found: /data/reference.fa" | python -c \
  "from workflow_composer.diagnosis import ErrorDiagnosisAgent; agent = ErrorDiagnosisAgent(); import asyncio; print(asyncio.run(agent.diagnose(input())))"
```

**Expected:**
- [ ] OOM ‚Üí OUT_OF_MEMORY category
- [ ] File error ‚Üí FILE_NOT_FOUND category
- [ ] Suggestions generated
- [ ] Risk levels assigned

### 9Ô∏è‚É£ RESULTS (10 min)
```bash
pytest tests/test_results.py -v

# Or manually check outputs
ls -la data/results/*/
head -20 data/results/*/multiqc_report.html
```

**Verify:**
- [ ] MultiQC HTML renders
- [ ] File metadata captured
- [ ] Visualizations display
- [ ] Export works

### üîü DATA DISCOVERY (15 min)
```bash
pytest tests/test_data_discovery.py::TestDataDiscovery -v
```

**Manual Tests:**
```python
from workflow_composer.data.discovery import DataDiscovery

discovery = DataDiscovery()

# ENCODE search
results = discovery.search("human ChIP-seq H3K27ac", sources=['encode'], max_results=3)
print(results)

# GEO search
results = discovery.search("mouse brain RNA-seq", sources=['geo'], max_results=3)
print(results)

# Multi-source
results = discovery.search("reference genome GRCh38", sources=['encode','geo','ensembl'], max_results=5)
print(results)
```

---

## üêõ Troubleshooting

### LLM Server Not Available
```bash
# Check Ollama
ollama serve &
ollama pull llama3:8b

# Or set API key
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="..."
```

### SLURM Issues
```bash
# Check cluster
sinfo

# Check permissions
id
groups

# Check account
sacctmgr list user $USER

# Check partition limits
sinfo -p debug,standard
```

### Test Data Missing
```bash
# Create minimal test data
mkdir -p tests/test_data
mkdir -p data/results/test_sample/

# Create test FASTQ (1000 reads)
python -c "
import gzip
with gzip.open('tests/test_data/test_R1.fastq.gz', 'wt') as f:
    for i in range(1000):
        f.write(f'@read_{i}\nACGTACGTACGT\n+\nIIIIIIIIIIII\n')
"
```

### Performance Too Slow
```bash
# Check system resources
free -h
df -h
top -b -n 1

# Check network
ping -c 3 8.8.8.8
```

---

## üìä Success Criteria

### ‚úÖ PASS
- [ ] All 10 components ‚â•95% passing
- [ ] No crashes or exceptions
- [ ] All timings <2x SLA
- [ ] Results scientifically reasonable
- [ ] Full workflow <15 min end-to-end

### ‚ö†Ô∏è WARN
- [ ] 90-95% pass rate
- [ ] Performance 1.5-2x SLA
- [ ] Minor cosmetic issues

### ‚ùå FAIL
- [ ] <90% pass rate
- [ ] Critical path broken
- [ ] Performance >2x SLA
- [ ] Data loss or corruption
- [ ] Security issues

---

## üìù Documentation

### Test Results Template
Save as `test_results_20251126.md`:

```markdown
# Test Results - November 26, 2025

**Date:** 2025-11-26  
**Tester:** [Name]  
**Environment:** SLURM / [Details]  
**Duration:** [Time]

## Component Results

| Component | Status | Issues | Notes |
|-----------|--------|--------|-------|
| Frontend | PASS | - | All tabs working |
| Intent | PASS | - | Accuracy 95%+ |
| Tool Selection | PASS | - | All major types mapped |
| Module Mapping | PASS | - | Parameters validated |
| Workflow Gen | PASS | - | Syntax verified |
| Execution | PASS | - | SLURM working |
| Monitoring | PASS | - | Real-time updates |
| Diagnosis | PASS | - | 4/4 error types detected |
| Results | PASS | - | Visualizations working |
| Discovery | PASS | - | Multi-source search <30s |

## Issues Found

### Critical
- [None]

### High Priority
- [None]

### Medium Priority
- [None]

### Low Priority
- [None]

## Performance Metrics

| Component | Time | SLA | Status |
|-----------|------|-----|--------|
| Intent Parsing | 85ms | 200ms | ‚úì |
| Tool Selection | 45ms | 100ms | ‚úì |
| Module Mapping | 250ms | 300ms | ‚úì |
| Workflow Gen | 800ms | 1000ms | ‚úì |
| Diagnosis | 120ms | 500ms | ‚úì |
| Discovery (3 sources) | 22s | 30s | ‚úì |

## Recommendation

**‚úÖ READY TO DEPLOY**

All tests passing. Performance within SLA. Recommend production deployment.
```

---

## üîó Useful Commands

```bash
# Show test structure
find tests -name "*.py" -type f | sort

# Run with coverage
pytest tests/ --cov=src/workflow_composer --cov-report=html

# Run specific test class
pytest tests/test_diagnosis.py::TestErrorDiagnosisAgent -v

# Run with markers
pytest tests/ -m "not slow" -v

# Parallel testing (if supported)
pytest tests/ -n 4

# Debug mode
pytest tests/test_diagnosis.py -vvv -s

# Generate test report
pytest tests/ --html=report.html --self-contained-html

# Check configuration
python -c "from workflow_composer.config import load_config; print(load_config())"

# List available analysis types
python -c "from workflow_composer.core import AnalysisType; print([t.value for t in AnalysisType])"

# List available tools
python -c "from workflow_composer.core import ToolSelector; selector = ToolSelector(); print(selector.tools)"

# Check installed packages
pip list | grep -E "nextflow|nf-core|workflow"
```

---

## ‚è±Ô∏è Estimated Timing

| Component | Time | Notes |
|-----------|------|-------|
| Frontend | 15 min | Manual + automated |
| Intent | 5 min | Quick test |
| Tool Selection | 5 min | Quick test |
| Module Mapping | 10 min | Parameter checking |
| Workflow Gen | 10 min | Lint + verify |
| Execution | 15 min | Submit + monitor |
| Monitoring | 10 min | Status tracking |
| Diagnosis | 10 min | Error patterns |
| Results | 10 min | Output scanning |
| Discovery | 15 min | API searches |
| **TOTAL** | **~2 hours** | Buffer for issues |

---

## üéØ Priorities

### Must Test (Critical Path)
1. Intent Parsing ‚Üí ‚úÖ
2. Tool Selection ‚Üí ‚úÖ
3. Workflow Generation ‚Üí ‚úÖ
4. Diagnosis ‚Üí ‚úÖ
5. Results ‚Üí ‚úÖ

### Should Test (Important)
6. Module Mapping ‚Üí ‚ö†Ô∏è
7. Data Discovery ‚Üí ‚ö†Ô∏è
8. Frontend ‚Üí ‚ö†Ô∏è

### Nice to Test (Nice-to-Have)
9. Execution ‚Üí üîÑ
10. Monitoring ‚Üí üîÑ

---

## üìû Support

If issues arise:
1. Check logs: `.nextflow.log`, `slurm-*.out`
2. Review error message: look in `DIAGNOSIS` section
3. Check system resources: `free -h`, `df -h`
4. Verify API connections: curl, telnet
5. Escalate if: critical path broken, data corrupted

---

**Good luck with testing tomorrow! üöÄ**

