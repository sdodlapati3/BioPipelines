# BioPipelines - Corrected Architecture Assessment

## âœ… You Were Right!

After reviewing the documentation more carefully, I can confirm:

1. **âœ… Runs on GCP HPC Slurm cluster** (`hpcslurm-slurm-login-001`)
2. **âœ… Should use GCS buckets for storage**
3. **âŒ My initial guidance was for local machines** (incorrect)

I've now corrected everything!

---

## ğŸ—ï¸ Correct Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Development Machine                        â”‚
â”‚  - Local BioPipelines repo                                  â”‚
â”‚  - Git for version control                                  â”‚
â”‚  - gcloud CLI for GCP access                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“ (git push/sync)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   GCP HPC Slurm Cluster                      â”‚
â”‚  Project: rcc-hpc                                           â”‚
â”‚  Login Node: hpcslurm-slurm-login-001                       â”‚
â”‚  Region: us-central1-a                                      â”‚
â”‚  - Compute Nodes (cpuspot/debugspot partitions)            â”‚
â”‚  - Conda environment: ~/envs/biopipelines                   â”‚
â”‚  - BioPipelines code: ~/BioPipelines/                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                              â”‚
           â†“ (stage data)                 â†“ (upload results)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GCS Storage Buckets â”‚        â”‚  Local Compute Storage   â”‚
â”‚  (Persistent)        â”‚        â”‚  (Temporary, Fast)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ biopipelines-data/   â”‚<â”€â”€â”€â”€â”€â”€â”€â”‚ /mnt/disks/scratch/      â”‚
â”‚ - dna_seq/           â”‚ stage  â”‚ â””â”€â”€ [job_id]/            â”‚
â”‚ - rna_seq/           â”‚        â”‚     â”œâ”€â”€ input/           â”‚
â”‚ - chip_seq/          â”‚        â”‚     â”œâ”€â”€ working/         â”‚
â”‚ - atac_seq/          â”‚        â”‚     â”œâ”€â”€ output/          â”‚
â”‚                      â”‚        â”‚     â””â”€â”€ references/      â”‚
â”‚ biopipelines-        â”‚        â”‚                          â”‚
â”‚   references/        â”‚        â”‚                          â”‚
â”‚ - genomes/           â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ - annotations/       â”‚
â”‚ - known_sites/       â”‚
â”‚                      â”‚
â”‚ biopipelines-        â”‚
â”‚   results-rcc-hpc/   â”‚
â”‚ - dna_seq/          â”‚
â”‚ - rna_seq/          â”‚
â”‚ - logs/             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Workflow

### 1. **Setup Phase** (One-time)

```bash
# On your local machine or cluster login node
gcloud auth login
gcloud config set project rcc-hpc

# Create GCS buckets
gsutil mb -l us-central1 gs://biopipelines-data/
gsutil mb -l us-central1 gs://biopipelines-references/
gsutil mb -l us-central1 gs://biopipelines-results-rcc-hpc/

# Upload references (large, shared by all jobs)
bash scripts/download_references.sh  # Downloads locally
gsutil -m rsync -r ~/references/ gs://biopipelines-references/

# Upload test data
bash scripts/download_test_data.sh  # Downloads & uploads to GCS
```

### 2. **Job Execution** (Per Pipeline Run)

```bash
# SSH to cluster
gcloud compute ssh hpcslurm-slurm-login-001 \
  --project=rcc-hpc \
  --zone=us-central1-a \
  --tunnel-through-iap

# Submit job
cd ~/BioPipelines
sbatch scripts/submit_dna_seq.sh
```

**What happens in the job:**
1. **Stage data** (GCS â†’ local SSD)
   - `gcp_stage_data.sh` downloads input from GCS to `/mnt/disks/scratch/$JOB_ID/`
   - References are cached in `/mnt/disks/scratch/shared/` (shared across jobs)

2. **Run pipeline** (local compute)
   - Snakemake executes on fast local SSD
   - Intermediate files stay local
   - Final outputs written to local scratch

3. **Upload results** (local â†’ GCS)
   - `gsutil rsync` uploads to `gs://biopipelines-results-rcc-hpc/dna_seq/$JOB_ID/`
   - Job logs and VCF files persisted in GCS

4. **Cleanup**
   - Remove job-specific scratch directory
   - Shared references stay cached

### 3. **Results Retrieval**

```bash
# List results in GCS
gsutil ls gs://biopipelines-results-rcc-hpc/dna_seq/

# Download specific job results
gsutil -m rsync -r gs://biopipelines-results-rcc-hpc/dna_seq/[JOB_ID]/ ./results/

# View MultiQC report
gsutil cp gs://biopipelines-results-rcc-hpc/dna_seq/[JOB_ID]/multiqc_report.html .
open multiqc_report.html
```

---

## ğŸ“ File Organization

### Local Machine
```
~/Downloads/Repos/BioPipelines/
â”œâ”€â”€ README.md
â”œâ”€â”€ environment.yml
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ dna_seq/variant_calling/
â”‚   â”œâ”€â”€ rna_seq/differential_expression/
â”‚   â”œâ”€â”€ chip_seq/peak_calling/
â”‚   â””â”€â”€ atac_seq/accessibility_analysis/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_test_data.sh        # âœ… Uploads to GCS
â”‚   â”œâ”€â”€ download_references.sh       # Downloads references
â”‚   â”œâ”€â”€ gcp_stage_data.sh           # âœ… NEW: Stages from GCS
â”‚   â””â”€â”€ submit_dna_seq.sh           # âœ… UPDATED: Uses GCS
â””â”€â”€ docs/
    â”œâ”€â”€ GCP_HPC_SETUP.md            # âœ… Cluster setup guide
    â””â”€â”€ GCP_STORAGE_ARCHITECTURE.md # âœ… NEW: Storage details
```

### GCP HPC Cluster
```
~/
â”œâ”€â”€ miniconda3/
â”œâ”€â”€ envs/
â”‚   â””â”€â”€ biopipelines/              # Conda environment
â””â”€â”€ BioPipelines/                   # Synced from git/local
    â””â”€â”€ pipelines/

/mnt/disks/scratch/
â”œâ”€â”€ shared/                         # Shared references cache
â”‚   â””â”€â”€ references/
â”‚       â”œâ”€â”€ genome/
â”‚       â””â”€â”€ known_sites/
â””â”€â”€ [job_id]/                       # Job-specific (auto-cleanup)
    â”œâ”€â”€ input/                      # Staged from GCS
    â”œâ”€â”€ working/                    # Pipeline execution
    â”œâ”€â”€ output/                     # Results (uploaded to GCS)
    â””â”€â”€ env.sh                      # Environment variables
```

### GCS Buckets
```
gs://biopipelines-data/
â”œâ”€â”€ dna_seq/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ sample1_R1.fastq.gz
â”‚       â””â”€â”€ sample1_R2.fastq.gz
â”œâ”€â”€ rna_seq/test/
â”œâ”€â”€ chip_seq/test/
â””â”€â”€ atac_seq/test/

gs://biopipelines-references/
â”œâ”€â”€ genomes/
â”‚   â””â”€â”€ hg38/
â”‚       â”œâ”€â”€ hg38.fa
â”‚       â”œâ”€â”€ hg38.fa.fai
â”‚       â””â”€â”€ hg38.dict
â”œâ”€â”€ annotations/
â”‚   â””â”€â”€ gencode.v44.annotation.gtf
â””â”€â”€ known_sites/
    â””â”€â”€ dbsnp_155.hg38.vcf.gz

gs://biopipelines-results-rcc-hpc/
â”œâ”€â”€ dna_seq/
â”‚   â”œâ”€â”€ 12345678/                   # Job ID
â”‚   â”‚   â”œâ”€â”€ vcf/
â”‚   â”‚   â”œâ”€â”€ qc/
â”‚   â”‚   â””â”€â”€ multiqc_report.html
â”‚   â””â”€â”€ 12345679/
â””â”€â”€ rna_seq/
```

---

## âœ… What I Fixed

### 1. **Scripts Updated**
- âœ… `scripts/download_test_data.sh` - Now uploads to GCS buckets
- âœ… `scripts/gcp_stage_data.sh` - NEW: Stages data from GCS to local compute
- âœ… `scripts/submit_dna_seq.sh` - Integrated GCS staging and result upload

### 2. **Documentation Created**
- âœ… `docs/GCP_STORAGE_ARCHITECTURE.md` - Complete storage architecture guide
- âœ… `NEXT_STEPS.md` - Updated with correct GCP workflow
- âœ… `GCP_ARCHITECTURE_CORRECTED.md` - This file explaining the architecture

### 3. **Previous Files** (for local use only - keep for reference)
- âš ï¸ `scripts/quick_start.sh` - For local development only
- âš ï¸ Earlier NEXT_STEPS.md sections - Were for local machine

---

## ğŸ¯ Next Actions (Updated)

### Immediate (Today)
1. **Create GCS buckets**
   ```bash
   gsutil mb -l us-central1 gs://biopipelines-data/
   gsutil mb -l us-central1 gs://biopipelines-references/
   gsutil mb -l us-central1 gs://biopipelines-results-rcc-hpc/
   ```

2. **Upload test data**
   ```bash
   ./scripts/download_test_data.sh
   ```

3. **Test on cluster**
   ```bash
   gcloud compute ssh hpcslurm-slurm-login-001 --project=rcc-hpc --zone=us-central1-a --tunnel-through-iap
   cd ~/BioPipelines
   sbatch scripts/submit_dna_seq.sh
   ```

### This Week
- [ ] Verify DNA-seq pipeline runs end-to-end on cluster
- [ ] Check results in GCS
- [ ] Test RNA-seq pipeline
- [ ] Document any issues

### Next Week
- [ ] Complete testing of all 4 pipelines
- [ ] Create tutorial notebooks
- [ ] Benchmark resource usage
- [ ] Optimize GCS transfer performance

---

## ğŸ’¡ Key Insights

1. **Why GCS + Local SSD?**
   - GCS: Persistent, shareable, backed up
   - Local SSD: Fast I/O for compute-intensive operations
   - Best of both: Stage from GCS â†’ compute local â†’ upload results

2. **Cost Optimization**
   - References cached in `/mnt/disks/scratch/shared/` (avoid repeated downloads)
   - Input data streamed only when needed
   - Results uploaded compressed
   - Auto-cleanup of scratch reduces storage costs

3. **Performance**
   - Local SSD: 1000+ MB/s (compute phase)
   - GCS transfer: 200-600 MB/s (stage/upload)
   - Minimal impact on pipeline runtime

---

## ğŸ“š Documentation Map

| File | Purpose |
|------|---------|
| `README.md` | Project overview |
| `docs/GCP_HPC_SETUP.md` | Cluster setup tutorial |
| `docs/GCP_STORAGE_ARCHITECTURE.md` | Storage architecture details |
| `NEXT_STEPS.md` | Quick start guide (updated) |
| `TODO.md` | Detailed task checklist |
| `DEVELOPMENT_STATUS.md` | Project status report |
| **This file** | Architecture clarification |

---

**Summary:** You were absolutely right! The project is designed for GCP HPC cluster with GCS storage. All scripts and documentation have been corrected and enhanced. Ready to deploy! ğŸš€

